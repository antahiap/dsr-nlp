{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antahiap/dsr-nlp/blob/main/notebooks/03_gensim_lsdyna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE3YdeaO9Nlo"
      },
      "source": [
        "# Using Gensim to create word embeddings for LSDYNA MAnual\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install wget (if not already installed)\n",
        "!apt-get -qq install wget\n",
        "\n",
        "# Download a specific file from the GitHub repository\n",
        "!wget \"https://github.com/antahiap/dsr-nlp/tree/main/data/lsdyna_i_r13.txt\"\n",
        "!wget \"https://github.com/antahiap/dsr-nlp/tree/main/data/lsdyna_ii_r13.txt\"\n"
      ],
      "metadata": {
        "id": "Ksg_eXqOmJRm",
        "outputId": "01884947-383e-46c4-db60-2ce4d92dff15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-09 09:29:37--  https://github.com/antahiap/dsr-nlp/tree/main/data/lsdyna_i_r13.txt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/antahiap/dsr-nlp/blob/main/data/lsdyna_i_r13.txt [following]\n",
            "--2023-08-09 09:29:38--  https://github.com/antahiap/dsr-nlp/blob/main/data/lsdyna_i_r13.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4589 (4.5K) [text/plain]\n",
            "Saving to: ‘lsdyna_i_r13.txt’\n",
            "\n",
            "lsdyna_i_r13.txt    100%[===================>]   4.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-09 09:29:38 (65.0 MB/s) - ‘lsdyna_i_r13.txt’ saved [4589/4589]\n",
            "\n",
            "--2023-08-09 09:29:38--  https://github.com/antahiap/dsr-nlp/tree/main/data/lsdyna_ii_r13.txt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/antahiap/dsr-nlp/blob/main/data/lsdyna_ii_r13.txt [following]\n",
            "--2023-08-09 09:29:38--  https://github.com/antahiap/dsr-nlp/blob/main/data/lsdyna_ii_r13.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4598 (4.5K) [text/plain]\n",
            "Saving to: ‘lsdyna_ii_r13.txt’\n",
            "\n",
            "lsdyna_ii_r13.txt   100%[===================>]   4.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-09 09:29:39 (60.2 MB/s) - ‘lsdyna_ii_r13.txt’ saved [4598/4598]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w7EsFY_LGkST",
        "outputId": "a687f614-5a60-47c7-ea97-a58c13d55fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  lsdyna_ii_r13.txt  lsdyna_i_r13.txt  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du12KNBf9eE9"
      },
      "source": [
        "## Import all necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cPxWl1qt9b_b",
        "outputId": "cee1ef10-085f-4613-9b80-aa8064ce4406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "import os\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy import spatial\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chO2MMAB9pnJ"
      },
      "source": [
        "## Train Gensim.\n",
        "\n",
        "Here we feed all the text data into Gensim to train Word2Vec.\n",
        "\n",
        "- [Gensim homepage](https://radimrehurek.com/gensim/).\n",
        "- [Wikipedia: Word2Vec](https://en.wikipedia.org/wiki/Word2vec)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim import utils\n",
        "\n",
        "class MyCorpus:\n",
        "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.lines = []\n",
        "\n",
        "        files = os.listdir(\".\")\n",
        "        files = [file for file in files if file.endswith(\".txt\")]\n",
        "        print(f\"Found {len(files)} files\")\n",
        "\n",
        "        for file in files:\n",
        "            print(file)\n",
        "            for line in open(file):\n",
        "                self.lines += [line]\n",
        "        print(f\"Got {len(self.lines)} lines.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        for line in self.lines:\n",
        "            preprocessed_line = utils.simple_preprocess(line)\n",
        "            yield preprocessed_line"
      ],
      "metadata": {
        "id": "db-sgHN0SvE0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v0pFRf0JGcZ0",
        "outputId": "b3f6013f-f394-4c54-a71d-3e094f8db964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 files\n",
            "Got 2 lines.\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import gensim.models\n",
        "\n",
        "sentences = MyCorpus()\n",
        "\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=sentences,\n",
        "    sg=1,\n",
        "    vector_size=300,\n",
        "    window=20,\n",
        "    min_count=3,\n",
        "    workers=multiprocessing.cpu_count()\n",
        ")\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY4d0XOm9tyW"
      },
      "source": [
        "## Find most similar words.\n",
        "\n",
        "With vectors it is easy to find the nearest neighbours.\n",
        "\n",
        "Note: Feel free to experiment with your own words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the vocabulary\n",
        "vocabulary = model.wv.key_to_index\n",
        "\n",
        "# Print the vocabulary\n",
        "for word in vocabulary:\n",
        "    print(word)\n",
        ""
      ],
      "metadata": {
        "id": "aKrtGIRQo468",
        "outputId": "9b4dd555-a393-4586-f3f3-fc32eec3d454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "null\n",
            "false\n",
            "name\n",
            "nlp\n",
            "dsr\n",
            "path\n",
            "txt\n",
            "antahiap\n",
            "contenttype\n",
            "data\n",
            "true\n",
            "file\n",
            "com\n",
            "https\n",
            "github\n",
            "main\n",
            "directory\n",
            "lsdyna_i_r\n",
            "lsdyna_ii_r\n",
            "pdf\n",
            "ls\n",
            "settings\n",
            "dismiss\n",
            "blob\n",
            "notice\n",
            "new\n",
            "gitignore\n",
            "totalcount\n",
            "items\n",
            "envs\n",
            "img\n",
            "notebooks\n",
            "src\n",
            "about\n",
            "readme\n",
            "md\n",
            "changes\n",
            "propose\n",
            "or\n",
            "make\n",
            "to\n",
            "in\n",
            "signed\n",
            "be\n",
            "must\n",
            "you\n",
            "creating\n",
            "docs\n",
            "and\n",
            "requirements\n",
            "symbols\n",
            "ce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JQ9oSWSZGf7l",
        "outputId": "813744f1-bb44-43cc-f318-44cad4b7b970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('txt', 0.9993817210197449),\n",
              " ('main', 0.9993041753768921),\n",
              " ('ce', 0.9992712736129761),\n",
              " ('data', 0.9992510080337524),\n",
              " ('totalcount', 0.9992466568946838),\n",
              " ('md', 0.9992452263832092),\n",
              " ('file', 0.9992308020591736),\n",
              " ('gitignore', 0.9992303252220154),\n",
              " ('directory', 0.9992228150367737),\n",
              " ('settings', 0.9992197155952454),\n",
              " ('lsdyna_i_r', 0.9992177486419678),\n",
              " ('path', 0.9992145895957947),\n",
              " ('in', 0.9991920590400696),\n",
              " ('or', 0.9991906881332397),\n",
              " ('notebooks', 0.9991894960403442),\n",
              " ('img', 0.9991830587387085),\n",
              " ('make', 0.9991651773452759),\n",
              " ('to', 0.9991651773452759),\n",
              " ('about', 0.9991628527641296),\n",
              " ('you', 0.9991617798805237)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.wv.most_similar(\"requirements\", topn=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyt_EaVm9wtc"
      },
      "source": [
        "## Plot word similarities.\n",
        "\n",
        "That was just one word. Let us generate a similarity matrix of a lot of words. Again, use your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zSh3oR5WIV-Q",
        "outputId": "cec12df9-139c-47ab-ce5a-7d8da4faa74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f81bc52e8969>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34m\"witch\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m ]\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mplot_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-f81bc52e8969>\u001b[0m in \u001b[0;36mplot_similarities\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f81bc52e8969>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \"\"\"\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'harry' not present\""
          ]
        }
      ],
      "source": [
        "def plot_similarities(words):\n",
        "    features = [np.array(model.wv[word]) for word in words]\n",
        "\n",
        "    similarities = np.zeros((len(features), len(features)))\n",
        "    for index1, feature1 in enumerate(features):\n",
        "        for index2, feature2 in enumerate(features):\n",
        "            similarities[index1, index2] = 1 - spatial.distance.cosine(feature1, feature2)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    g = sns.heatmap(\n",
        "        similarities,\n",
        "        annot=True,\n",
        "        xticklabels=words,\n",
        "        yticklabels=words,\n",
        "        cmap=\"inferno\"\n",
        "    )\n",
        "    g.set_xticklabels(words, rotation=90)\n",
        "    g.set_yticklabels(words, rotation=0)\n",
        "    g.set_title(\"Semantic Similarity\")\n",
        "\n",
        "words = [\n",
        "    \"harry\",\n",
        "    \"hermione\",\n",
        "    \"ron\",\n",
        "    \"fred\",\n",
        "    \"george\",\n",
        "    \"snape\",\n",
        "    \"wand\",\n",
        "    \"snitch\",\n",
        "    \"marauder\",\n",
        "    \"map\",\n",
        "    \"hogwarts\",\n",
        "    \"slytherin\",\n",
        "    \"gryffindor\",\n",
        "    \"hufflepuff\",\n",
        "    \"ravenclaw\",\n",
        "    \"voldemort\",\n",
        "    \"tom\",\n",
        "    \"horcrux\",\n",
        "    \"snake\",\n",
        "    \"nagini\",\n",
        "    \"wizard\",\n",
        "    \"witch\"\n",
        "]\n",
        "plot_similarities(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX9onfgV93w0"
      },
      "source": [
        "# Thank you!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}